{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:22:31.631422Z","iopub.status.busy":"2024-06-03T22:22:31.630630Z","iopub.status.idle":"2024-06-03T22:23:58.907391Z","shell.execute_reply":"2024-06-03T22:23:58.906216Z","shell.execute_reply.started":"2024-06-03T22:22:31.631387Z"},"trusted":true},"outputs":[],"source":["import os\n","if not os.path.exists('hpt') and os.getcwd() == '/kaggle/working':\n","    #!pip install lion-pytorch\n","    !git clone https://github.com/Milpo1/hpt\n","    os.chdir('hpt')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:23:58.910067Z","iopub.status.busy":"2024-06-03T22:23:58.909742Z","iopub.status.idle":"2024-06-03T22:23:59.424709Z","shell.execute_reply":"2024-06-03T22:23:59.423631Z","shell.execute_reply.started":"2024-06-03T22:23:58.910034Z"},"trusted":true},"outputs":[],"source":["import shutil\n","import random\n","from matplotlib import image as mpimg\n","import numpy as np\n","from skimage.transform import resize\n","random.seed(42)\n","\n","data_method = 'word' # word / tile\n","\n","del_dirs = ['data','test','test_sources']\n","for d in del_dirs:\n","    if os.path.exists(d):\n","        shutil.rmtree(d)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:23:59.426420Z","iopub.status.busy":"2024-06-03T22:23:59.425957Z","iopub.status.idle":"2024-06-03T22:23:59.431251Z","shell.execute_reply":"2024-06-03T22:23:59.430341Z","shell.execute_reply.started":"2024-06-03T22:23:59.426392Z"},"trusted":true},"outputs":[],"source":["# !ls sources/author1/skany/\n","files = os.listdir('sources/author1/skany')\n","image_files = [file for file in files if file.endswith('bmp')]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:23:59.432569Z","iopub.status.busy":"2024-06-03T22:23:59.432310Z","iopub.status.idle":"2024-06-03T22:23:59.448616Z","shell.execute_reply":"2024-06-03T22:23:59.447781Z","shell.execute_reply.started":"2024-06-03T22:23:59.432545Z"},"trusted":true},"outputs":[],"source":["\n","def select_test_image_from_each_folder(main_directory, test_source_dir):\n","    random_images = []\n","    if not os.path.exists(test_source_dir):\n","        os.makedirs(test_source_dir) \n","    # Iterate over each subfolder in the main directory\n","    for folder_name in os.listdir(main_directory):\n","        folder_path = os.path.join(main_directory, folder_name)\n","        if os.path.isdir(folder_path):\n","            # Get a list of all image files in the subfolder\n","            subfolder_path = os.path.join(folder_path, 'skany')\n","            image_files = [file for file in os.listdir(subfolder_path) if file.endswith(('.bmp'))]\n","            # Select a random image from the list\n","            if image_files:\n","                target_dir = os.path.join(test_source_dir,folder_name)\n","                target_path = os.path.join(target_dir,'word_places.txt')\n","                source_path = os.path.join(folder_path,'word_places.txt')\n","                if not os.path.exists(target_dir):\n","                    os.makedirs(target_dir)\n","                shutil.copy(source_path, target_path)\n","                for i in range(2):\n","                    random_image = random.choice(image_files)\n","                    target_dir = os.path.join(test_source_dir,folder_name,'skany')\n","                    target_path = os.path.join(target_dir,random_image)\n","                    source_path = os.path.join(subfolder_path,random_image)\n","                    if not os.path.exists(target_dir):\n","                        os.makedirs(target_dir) \n","                    shutil.move(source_path, target_path)\n","                    image_files.remove(random_image)\n","\n","train_source_dir = 'sources'\n","test_source_dir = 'test_sources'\n","select_test_image_from_each_folder(train_source_dir, test_source_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2024-06-03T22:23:59.451494Z","iopub.status.busy":"2024-06-03T22:23:59.451104Z","iopub.status.idle":"2024-06-03T22:24:07.870032Z","shell.execute_reply":"2024-06-03T22:24:07.869272Z","shell.execute_reply.started":"2024-06-03T22:23:59.451467Z"},"trusted":true},"outputs":[],"source":["def trim_image(image, trim_percentage=0.9):\n","    new_height = int(image.shape[0] * trim_percentage)\n","    new_width = int(image.shape[1] * trim_percentage)\n","\n","    offset_height = (image.shape[0] - new_height) // 2\n","    offset_width = (image.shape[1] - new_width) // 2\n","\n","    cropped_image = image[offset_height:offset_height+new_height, offset_width:offset_width+new_width]\n","\n","    return cropped_image\n","# max_num_of_words_per_author = 400000\n","\n","def crop(n, max_n):\n","    return max(0,n) if n <= max_n else max_n\n","\n","def merge(l, start, end):\n","    sub_merged = \"\"\n","    for o in l[start:end+1]:\n","        sub_merged = sub_merged+o\n","    merged = l[:start] + [sub_merged] + l[end+1:]\n","    return merged\n","\n","def word_source(source_path, dest_path):\n","    num_of_authors = 8\n","    h_l, w_l = [], []\n","    for author_no in range(num_of_authors):\n","        file_path = source_path+'/author' + str(author_no + 1)\n","        file_desc_name = file_path + \"/word_places.txt\"\n","        files = os.listdir(file_path+'/skany')\n","        image_files = [file for file in files if file.endswith('bmp')]\n","        file_desc_ptr = open(file_desc_name, 'r', errors='ignore')\n","        text = file_desc_ptr.read()\n","        lines = text.split('\\n')\n","        number_of_lines = lines.__len__() - 1\n","        row_values = lines[0].split()\n","        number_of_values = row_values.__len__()\n","\n","        num_of_words = 0\n","        image_file_name_prev = \"\"\n","        subimage_dir = dest_path+'/a'+str(author_no + 1)\n","\n","        if not os.path.exists(subimage_dir):\n","            os.makedirs(subimage_dir)   \n","\n","        for i in range(number_of_lines):\n","            row_values = lines[i].split()\n","\n","            if len(row_values) > 6:\n","                row_values = merge(row_values,1,len(row_values)-5)\n","            elif len(row_values) < 6:\n","                continue\n","\n","            if row_values[0] != '%':\n","                num_of_words += 1\n","                number_of_values = len(row_values)\n","\n","                image_source = row_values[0][1:-1].replace('\\\\','/')\n","                if image_source[6:] not in image_files:\n","                    continue\n","                image_file_name = source_path+\"/author\" + str(author_no + 1) + \"/\" + image_source\n","                \n","                if image_file_name != image_file_name_prev:   \n","                    image = mpimg.imread(str(image_file_name))\n","                    image_file_name_prev = image_file_name\n","                word = row_values[1]\n","\n","                if word == \"<brak>\":\n","                    continue\n","\n","                row1, column1, row2, column2 = int(row_values[2]), int(row_values[3]), \\\n","                    int(row_values[4]), int(row_values[5])\n","\n","                height, width = len(image), len(image[0])\n","                row1, row2 =  crop(row1,height), crop(row2,height)\n","                column1, column2 =  crop(column1,width), crop(column2,width)\n","\n","                subimage = image[min(row1,row2):max(row1,row2),\n","                                min(column1,column2):max(column1,column2)] \n","#                 subimage = trim_image(subimage,0.95)\n","                h_l.append(len(subimage))\n","                w_l.append(len(subimage[0]))\n","\n","                #subimage = resize(subimage, (65,154))\n","                mpimg.imsave(subimage_dir+'/'+str(num_of_words)+'.bmp',subimage)\n","\n","            # if num_of_words >= max_num_of_words_per_author: break\n","\n","\n","        file_desc_ptr.close()\n","        \n","if data_method == 'word':\n","    word_source('sources','train_data')\n","    word_source('test_sources','test_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:07.871494Z","iopub.status.busy":"2024-06-03T22:24:07.871168Z","iopub.status.idle":"2024-06-03T22:24:07.886057Z","shell.execute_reply":"2024-06-03T22:24:07.885168Z","shell.execute_reply.started":"2024-06-03T22:24:07.871463Z"},"trusted":true},"outputs":[],"source":["th = 0.94\n","num_of_authors = 8\n","hor_tile = 8\n","def is_empty_subimage(subimage, threshold=th):\n","    gray_subimage = np.mean(subimage, axis=2)\n","\n","    white_pixels = np.sum(gray_subimage > 220)\n","    total_pixels = gray_subimage.shape[0] * gray_subimage.shape[1]\n","    white_percentage = white_pixels / total_pixels\n","\n","    return white_percentage > threshold\n","\n","def trim_image(image, trim_percentage=0.9):\n","    new_height = int(image.shape[0] * trim_percentage)\n","    new_width = int(image.shape[1] * trim_percentage)\n","\n","    offset_height = (image.shape[0] - new_height) // 2\n","    offset_width = (image.shape[1] - new_width) // 2\n","\n","    cropped_image = image[offset_height:offset_height+new_height, offset_width:offset_width+new_width]\n","\n","    return cropped_image\n","\n","def tile_folder(source_dir, dest_dir):\n","    files = os.listdir(source_dir)\n","    image_files = [file for file in files if file.endswith('bmp')]\n","    subimage_no = 0\n","    for image_file in image_files:\n","        image_file_name = source_dir + \"/\" + image_file\n","        image = mpimg.imread(str(image_file_name))\n","        image = trim_image(image)\n","        image_h, image_w = len(image), len(image[0])\n","        ver_tile = int(hor_tile * image_h/image_w)\n","        tile_size = int(image_w / hor_tile)\n","        for yp in range(ver_tile):\n","            for xp in range(hor_tile):\n","                subimage = image[yp*tile_size:(yp+1)*tile_size,\n","                                 xp*tile_size:(xp+1)*tile_size]\n","\n","                if not is_empty_subimage(subimage):\n","                    subimage_no+=1\n","                    mpimg.imsave(dest_dir+'/'+str(subimage_no)+'.bmp',subimage)     \n","    print(f'Subimages for {dest_dir}: {subimage_no}')\n","\n","def tile_source(source_path, dest_path):\n","    print(f'th: {th} hor tile: {hor_tile}')\n","    for author_no in range(num_of_authors):\n","        source_dir = source_path+'/author'+str(author_no + 1)+'/skany'\n","        label_dir = dest_path+'/a'+str(author_no + 1)\n","        if not os.path.exists(label_dir):\n","            os.makedirs(label_dir)  \n","        tile_folder(source_dir,label_dir)\n","        \n","if data_method == 'tile':\n","    tile_source('sources','train_data')\n","    tile_source('test_sources','test_data')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:07.887763Z","iopub.status.busy":"2024-06-03T22:24:07.887508Z","iopub.status.idle":"2024-06-03T22:24:14.296298Z","shell.execute_reply":"2024-06-03T22:24:14.295474Z","shell.execute_reply.started":"2024-06-03T22:24:07.887740Z"},"trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","from torch.utils.data import  DataLoader, random_split\n","class AuthorImagesDataset:\n","    def __init__(self, root_dir, batch_size:int,DataProcent:float,transform=None):\n","        self.BATCH_SIZE=batch_size\n","        self.root_dir = root_dir\n","        self.transform = transform if transform else transforms.ToTensor()\n","        self.dataset = datasets.ImageFolder(root=self.root_dir, transform=self.transform)\n","\n","        subset_length = int(len(self.dataset) * DataProcent)\n","        rest_length = len(self.dataset) - subset_length\n","        self.subset_data, _ = random_split(self.dataset, [subset_length, rest_length])\n","\n","        # Two separate AuthorImagesDataset objects are later created for train and test\n","        test_length = 0#int(len(self.subset_data) * 0.2)\n","        train_length = len(self.subset_data) - test_length\n","\n","        # Split the dataset\n","        self.train_data, self.test_data = random_split(self.subset_data, [train_length, test_length])\n","        \n","        self.into_data_loaders()\n","\n","    def into_data_loaders(self):\n","\n","\n","        self.train_dataloader= DataLoader(dataset=self.train_data, # use custom created train Dataset\n","                                     batch_size=self.BATCH_SIZE, # how many samples per batch?\n","                                    num_workers=4, # how many subprocesses to use for data loading? (higher = more)\n","                                    # pin_memory=True,\n","                                     shuffle=True) # shuffle the data?\n","\n","        self.test_dataloader = DataLoader(dataset=self.test_data, # use custom created test Dataset\n","                                    batch_size=self.BATCH_SIZE, \n","                                    num_workers=4, \n","                                    shuffle=False) # don't usually need to shuffle testing data\n","        \n","    \n","    def __len__(self):\n","        return len(self.dataset) \n","            \n","    \n","def create_dataloaders(\n","        DatasetDir:str,\n","        transform: transforms.Compose, \n","        batch_size: int,\n","        DataProcent:float\n","):\n","    s=AuthorImagesDataset(DatasetDir,batch_size,DataProcent,transform)\n","    \n","    return s.train_dataloader,s.test_dataloader,s.dataset.classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:14.297892Z","iopub.status.busy":"2024-06-03T22:24:14.297507Z","iopub.status.idle":"2024-06-03T22:24:14.320607Z","shell.execute_reply":"2024-06-03T22:24:14.319755Z","shell.execute_reply.started":"2024-06-03T22:24:14.297867Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Contains functions for training and testing a PyTorch model.\n","\"\"\"\n","\n","import torch\n","from tqdm.auto import tqdm\n","from typing import Dict, List, Tuple\n","\n","def train_step(model: torch.nn.Module, \n","               dataloader: torch.utils.data.DataLoader, \n","               loss_fn: torch.nn.Module, \n","               optimizer: torch.optim.Optimizer,\n","               device: torch.device) -> Tuple[float, float]:\n","    \n","    \n","    model.train()\n","    train_loss,train_acc=0,0\n","\n","    for batch, (X,y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","        \n","        y_logits=model(X)\n","\n","        loss=loss_fn(y_logits,y)\n","        train_loss+=loss.item()\n","\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","        \n","        y_pred_class=y_logits.argmax(dim=1)\n","        train_acc+=(y_pred_class==y).sum().item()/len(y_logits)\n","\n","    train_loss=train_loss/len(dataloader)\n","    train_acc=train_acc/len(dataloader)\n","    \n","    return train_loss,train_acc\n","\n","\n","def test_step(model: torch.nn.Module, \n","              dataloader: torch.utils.data.DataLoader, \n","              loss_fn: torch.nn.Module,\n","              device: torch.device) -> Tuple[float, float]:\n","    \n","    model.eval()\n","    test_loss,test_acc=0,0\n","\n","    with torch.inference_mode():\n","        for batch, (X,y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)\n","            y_logits=model(X)\n","            \n","            loss=loss_fn(y_logits,y)\n","            test_loss+=loss.item()\n","\n","            y_pred_class=y_logits.argmax(dim=1)\n","            test_acc+=(y_pred_class==y).sum().item()/len(y_logits)\n","\n","    test_loss=test_loss/len(dataloader)\n","    test_acc=test_acc/len(dataloader)\n","\n","    return test_loss,test_acc\n","\n","\n","def train(model: torch.nn.Module, \n","          train_dataloader: torch.utils.data.DataLoader, \n","          test_dataloader: torch.utils.data.DataLoader, \n","          optimizer: torch.optim.Optimizer,\n","          loss_fn: torch.nn.Module,\n","          epochs: int,\n","          device: torch.device) -> Dict[str, List]:\n","    \n","    results = {\"train_loss\": [],\n","    \"train_acc\": [],\n","    \"test_loss\": [],\n","    \"test_acc\": []\n","    }\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss, train_acc = train_step(model=model,\n","                                            dataloader=train_dataloader,\n","                                            loss_fn=loss_fn,\n","                                            optimizer=optimizer,\n","                                            device=device)\n","        test_loss, test_acc = test_step(model=model,\n","            dataloader=test_dataloader,\n","            loss_fn=loss_fn,\n","            device=device)\n","\n","        print(\n","            f\"Epoch: {epoch+1} | \"\n","            f\"train_loss: {train_loss:.4f} | \"\n","            f\"train_acc: {train_acc:.4f} | \"\n","            f\"test_loss: {test_loss:.4f} | \"\n","            f\"test_acc: {test_acc:.4f}\"\n","        )\n","\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","        if train_acc >= 0.99 and test_acc >= 0.99:\n","            return results\n","    return results\n","\n","\n","\n","def plot_loss_curves(results: Dict[str, List[float]]):\n","    import matplotlib.pyplot as plt\n","    \"\"\"Plots training curves of a results dictionary.\n","\n","    Args:\n","        results (dict): dictionary containing list of values, e.g.\n","            {\"train_loss\": [...],\n","             \"train_acc\": [...],\n","             \"test_loss\": [...],\n","             \"test_acc\": [...]}\n","    \"\"\"\n","    \n","    # Get the loss values of the results dictionary (training and test)\n","    loss = results['train_loss']\n","    test_loss = results['test_loss']\n","\n","    # Get the accuracy values of the results dictionary (training and test)\n","    accuracy = results['train_acc']\n","    test_accuracy = results['test_acc']\n","\n","    # Figure out how many epochs there were\n","    epochs = range(len(results['train_loss']))\n","\n","    # Setup a plot \n","    plt.figure(figsize=(15, 7))\n","\n","    # Plot loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, loss, label='train_loss')\n","    plt.plot(epochs, test_loss, label='test_loss')\n","\n","    plt.title('Loss')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    # plt.show()\n","\n","    # Plot accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, accuracy, label='train_accuracy')\n","    plt.plot(epochs, test_accuracy, label='test_accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:14.322005Z","iopub.status.busy":"2024-06-03T22:24:14.321742Z","iopub.status.idle":"2024-06-03T22:24:14.343310Z","shell.execute_reply":"2024-06-03T22:24:14.342466Z","shell.execute_reply.started":"2024-06-03T22:24:14.321981Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Contains PyTorch model code to ResNet50-ResNet152 models.\n","\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","\n","class ResNetblock(nn.Module):\n","\n","    def __init__(self,in_channels,out_channels,stride=1,identity_downsample=None) -> None:\n","        super(ResNetblock,self).__init__()\n","\n","        self.expansion=4\n","\n","        self.conv1=nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=stride)\n","        self.bn1=nn.BatchNorm2d(out_channels)\n","       \n","        self.conv2=nn.Conv2d(in_channels=out_channels,out_channels=out_channels,kernel_size=3,padding=1,stride=1)\n","        self.bn2=nn.BatchNorm2d(out_channels)\n","       \n","        self.conv3=nn.Conv2d(in_channels=out_channels,out_channels=out_channels*self.expansion,kernel_size=3,padding=1,stride=1)\n","        self.bn3=nn.BatchNorm2d(out_channels*self.expansion)\n","        \n","        \n","        self.relu=nn.ReLU()\n","        self.dropout = nn.Dropout(p=0.01)\n","        self.identity_downsample=identity_downsample\n","    \n","    def forward(self,x):\n","        identity=x\n","        # print(f\"identity shape x{identity.shape}\")\n","        \n","        x=self.conv1(x)\n","        x=self.bn1(x)\n","        x=self.relu(x)\n","        # print(f\"after conv1 shape {x.shape}\")\n","\n","        x=self.conv2(x)\n","        x=self.bn2(x)\n","        # print(f\"after conv2 shape {x.shape}\")\n","\n","        # print(f\"before conv3 shape {x.shape}\")\n","        x=self.conv3(x)\n","        x=self.bn3(x)\n","        # print(f\"after conv3 shape {x.shape}\")\n","        \n","        if self.identity_downsample != None:\n","            identity=self.identity_downsample(identity)\n","            # print(f\"identity shape after downsample {identity.shape}\")\n","\n","        x+=identity\n","        x=self.relu(x)\n","        x=self.dropout(x)\n","        # print(f\"x shape {x.shape}\")\n","\n","        return x\n","    \n","\n","\n","class ResNet(nn.Module):\n","    '''\n","        Creates the ResNet50+ architecture\n","\n","        Replicates the ResNet50 architecture from the https://github.com/Machmurka/UnderstandingDeepLearning/blob/main/Learn%20PyTorch%20for%20Deep%20Learning/ResNet18layers.ipynb\n","        See the original architecture here: # https://arxiv.org/pdf/1512.03385.pdf\n","\n","    '''\n","    def __init__(self,block:ResNetblock,img_channels,num_classes,block_num:list) -> None:\n","        super(ResNet,self).__init__()\n","        \n","        self.in_channels=64\n"," \n","        self.conv1=nn.Conv2d(img_channels,64,kernel_size=7,stride=2,padding=3)\n","        self.bn1=nn.BatchNorm2d(64)\n","        self.relu=nn.ReLU()\n","        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n","\n","        self.layer2=self._make_layer(block,block_num[0],64,1)\n","        self.layer3=self._make_layer(block,block_num[1],128,2)\n","        self.layer4=self._make_layer(block,block_num[2],256,2)\n","        self.layer5=self._make_layer(block,block_num[3],512,2)\n","\n","        self.avg=nn.AvgPool2d((1,1))\n","        self.fc=nn.Linear(128*128*2,num_classes)\n","\n","\n","    def forward(self,x):\n","        x=self.conv1(x)\n","        x=self.bn1(x)\n","        x=self.relu(x)\n","        x=self.maxpool(x)\n","\n","        x=self.layer2(x)\n","        x=self.layer3(x)\n","        x=self.layer4(x)\n","        x=self.layer5(x)\n","        x=self.avg(x)\n","        x=x.reshape(x.shape[0],-1)\n","        x=self.fc(x)\n","        \n","        return x\n","    \n","    def _make_layer(self,block:ResNetblock,num_blocks,out_channels,stride):\n","        identity_downsample=None\n","        layers=[]\n","\n","        if stride!=1 or self.in_channels!=out_channels*4:\n","            identity_downsample=nn.Sequential(\n","                nn.Conv2d(self.in_channels,out_channels*4,1,stride,padding=0),\n","                nn.BatchNorm2d(out_channels*4)\n","            )\n","            # print(\"stride test\")\n","        \n","        layers.append(block(self.in_channels,out_channels=out_channels,stride=stride,identity_downsample=identity_downsample))\n","        self.in_channels=out_channels*4\n","\n","        for i in range(num_blocks-1):\n","            layers.append(block(self.in_channels,out_channels=out_channels))\n","\n","        return nn.Sequential(*layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:14.344770Z","iopub.status.busy":"2024-06-03T22:24:14.344501Z","iopub.status.idle":"2024-06-03T22:24:15.704249Z","shell.execute_reply":"2024-06-03T22:24:15.703402Z","shell.execute_reply.started":"2024-06-03T22:24:14.344747Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from torchvision import transforms\n","import torchvision.models as models\n","# Procent wykorzystania całych danych\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","train_data_dir='train_data'\n","test_data_dir='test_data'\n","print(device)\n","\n","DATA_PROCENT=1\n","NUM_EPOCHS = 15\n","BATCH_SIZE = 128\n","LEARNING_RATE = 5e-5\n","BLOCK_NUM=[3,4,6,3]\n","\n","data_transform= transforms.Compose([transforms.Resize(size=(128,128)),\n","                transforms.ToTensor(),\n","                ])\n","\n","train_dataloader, _, class_names = create_dataloaders(\n","    DatasetDir=train_data_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE,\n","    DataProcent=DATA_PROCENT\n",")\n","test_dataloader, _, class_names = create_dataloaders(\n","    DatasetDir=test_data_dir,\n","    transform=data_transform,\n","    batch_size=BATCH_SIZE,\n","    DataProcent=DATA_PROCENT\n",")\n","model = ResNet(ResNetblock,3,len(class_names),BLOCK_NUM)\n","model = nn.DataParallel(model)\n","model = model.to(device)\n","model.train()\n","loss_fn = torch.nn.CrossEntropyLoss()\n","#from lion_pytorch import Lion\n","#optimizer = Lion(model.parameters(), lr=1e-4, weight_decay=1e-2)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T22:24:15.706078Z","iopub.status.busy":"2024-06-03T22:24:15.705677Z"},"trusted":true},"outputs":[],"source":["print(f\"len train_dataloader {len(train_dataloader)*BATCH_SIZE}\")\n","print(f\"len test_dataloader {len(test_dataloader)*BATCH_SIZE}\")\n","\n","results=train(model=model,\n","                    train_dataloader=train_dataloader,\n","                    test_dataloader=test_dataloader,\n","                    loss_fn=loss_fn,\n","                    optimizer=optimizer,\n","                    epochs=NUM_EPOCHS,\n","                    device=device)\n","\n","plot_loss_curves(results)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","import matplotlib.pyplot as plt\n","import torch\n","\n","# Set the model to evaluation mode\n","model.eval()\n","\n","# Get some images from the training set\n","dataiter = iter(train_dataloader)\n","images, labels = next(dataiter)\n","\n","# Select a subset of images to display\n","rand = random.randint(0,32)\n","images_subset, labels_subset = images[rand:rand+5], labels[rand:rand+5]\n","\n","# Predict\n","with torch.no_grad():  # We don't need to calculate gradients here, so we disable gradient computation\n","    #images_flattened = images_subset.view(-1, input_size)\n","    outputs = model(images_subset)\n","    _, predicted = torch.max(outputs, 1)\n","\n","# Plot the images along with predicted and true labels\n","fig, axes = plt.subplots(1, 5, figsize=(12, 2.5))\n","for ax, image, pred, true in zip(axes, images_subset, predicted, labels_subset):\n","    image_np = image.cpu().numpy().transpose((1,2,0))\n","#     image_np = image_np * 0.5 + 0.5\n","    ax.imshow(image_np)\n","    \n","    ax.set_title(f'Predicted: {pred}\\nTrue: {true}')\n","    ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def test_cat_step(model: torch.nn.Module, \n","              dataloader: torch.utils.data.DataLoader, \n","              loss_fn: torch.nn.Module,\n","              device: torch.device,\n","              num_classes: int) -> Tuple[float, torch.Tensor]:\n","    \n","    model.eval()\n","    test_loss = 0\n","    correct_predictions = torch.zeros(num_classes, dtype=torch.float32, device=device)\n","    total_predictions = torch.zeros(num_classes, dtype=torch.float32, device=device)\n","\n","    with torch.inference_mode():\n","        for batch, (X, y) in enumerate(dataloader):\n","            X, y = X.to(device), y.to(device)\n","            y_logits = model(X)\n","            \n","            loss = loss_fn(y_logits, y)\n","            test_loss += loss.item()\n","            \n","            y_pred_class = y_logits.argmax(dim=1)\n","            \n","            for category in range(num_classes):\n","                category_mask = y == category\n","                correct_predictions[category] += (y_pred_class[category_mask] == y[category_mask]).sum().item()\n","                total_predictions[category] += category_mask.sum().item()\n","\n","    test_loss = test_loss / len(dataloader)\n","    test_acc = correct_predictions / total_predictions\n","\n","    return test_loss, test_acc\n","test_cat_step(model=model,\n","            dataloader=test_dataloader,\n","            loss_fn=loss_fn,\n","            device=device,\n","            num_classes=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(model,f'resnet{50 if BLOCK_NUM==[3,4,6,3] else 101 if BLOCK_NUM==[3,4,23,3] else ''}.pth')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
